## Guelderose

---

### Описание

Данный проект представляет собой своеобразный коннектор (его прототип) для асинхронной обработки заданий на распознавание.

UPD: Проект не завершен, по мере возможности будут добавляться улучшения.

### Конфигурация

В `config.yaml` устанавливаются значения для полей:

- `Redis`
  - `host` - хост сервера Redis.
  - `port` - порт сервера Redis.
  - `secret` - пароль для Auth в Redis.
  - `poll_delay_ms` - задержка (в миллисекундах) между проверками наличия сообщений в очереди.
  - `read_delay_ms` - задержка (в миллисекундах) между чтениями сообщений из очереди.
  - `queues` - имена очередей (ключи) в Redis.
    - `inbox` - имя входной очереди (для заданий на распознавание).
    - `outbox` - имя выходной очереди (для обработанных задач).
- `Kafka`
  - `group_id` - идентификатор группы потребителей Kafka.
  - `batch_size` - размер батча (количество сообщений), который потребляется за один раз.
  - `bootstrap_servers` - список адресов брокеров Kafka.
  - `topics` - имена топиков в Kafka.
    - `input` - имя топика для заданий на распознавание.
    - `output` - имя топика для (не)обработанных заданий.
- `Logging`
  - `log_level` - уровень детализации логов/трассировки.

***Важно!***  
Перед запуском сервиса необходимо убедиться, что вы переопределили все следующие переменные среды:
- APP__REDIS__SECRET="your_secure_redis_password"

### Детали реализации

При старте сервиса запускаются и начинаю выполняться:
- `outbox_daemon`  
  Это демон читающий сообщения из [outbox queue], и отправляющий их в Kafka.  
  Логика работы:  
  При старте сервиса, поднимается экземпляр в отдельном потоке.
  Демон с определенной периодичностью опрашивает [outbox queue], и при наличии сообщений отправляет их в Kafka.
- `kafka_consumer`  
  Это потребитель сообщений из Kafka.  
  Логика работы:  
  При старте сервиса, запускается Consumer в отдельном потоке.
  Consumer подключается к Kafka, и начинает вычитывать сообщения батчами (размером N).
  Все сообщения батча пушатся в [inbox queue].
  Далее [inbox queue] опрашивается, пока все задания из батча не уйдут в обработку. Только тогда этот батч коммитится, и берется следующий.

В данный момент очереди [inbox/outbox] реализованы как `Redis Lists`, где пишем в хвост очереди, читаем с начала.
В будущем желательно рассмотреть `Redis Stream` или `Apache Pulsar` - это даст гарантии обработки (в отличие от`Redis Lists`).

### Локальный запуск

1) Для установки `Rust` на Unix-подобные системы (MacOS, Linux, ...) - запускаем в терминале команду.
   По окончании загрузки вы получите последнюю стабильную версию Rust для вашей платформы, а так же последнюю версию Cargo.

```shell
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
```

2) Для проверки выполните следующую команду в терминале.  
   В случае успешной установки (шаг 1), вы увидите примерно это `cargo 1.89.0 ...`.

```shell
cargo --version
```

3) Клонируем проект из GitHub, открываем его, и выполняем следующие команды.

Проверяет код на возможность компиляции (без запуска).
```shell
cargo check
```

Сборка + запуск проекта (в режиме релиза с оптимизациями).
```shell
cargo run --release
```

UDP: Если вдруг у вас Windows, посмотрите [Инструкцию тут](https://forge.rust-lang.org/infra/other-installation-methods.html)

### Локальное развертывание

Чтобы развернуть проект локально в `Docker`, вам нужно:

1) Убедиться что `Docker daemon` запущен.
2) Открыть терминал в корне проекта, перейти в директорию `/docker`.
3) Выполнить команду (например `docker compose up -d`) - поднимутся зависимые сервисы (Redis, Kafka).
4) Зайти в контейнер Kafka, и выполнить команду создания топиков (например `kafka-topics --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test_input_topic`).
5) Запустить сам сервис (инструкция в разделе `Локальный запуск`).
6) Наслаждаться использованием. :wink:
