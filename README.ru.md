## Guelderose

---

### Описание

Данный проект представляет собой своеобразный коннектор для асинхронной обработки заданий на распознавание.

Данный сервис выполняет:
- Потребление сообщений (заданий на распознавание) из `Kafka` + отправка их в `inbox queue`.
- Получение результатов/ошибок из `outbox queue` и публикация  обратно в `Kafka`.
- Загрузку/выгрузку файлов для распознавания и результатов между файловыми хранилищами (`S3`).

Поддерживаемые виды распознаваний: "TypeOne", TypeTwo".

UPD: Проект не завершен, по мере возможности будут добавляться улучшения.

### Конфигурация

В `config.yaml` устанавливаются значения для полей:

- `S3`
  - `url` - адрес S3 хранилища.
  - `bucket` - имя используемого bucket.
  - `access_key` - ключ доступа к S3 хранилищу (опциональный параметр).
  - `secret_key` - секретный ключ для доступа в S3 хранилище (опциональный параметр).
  - `client_connection_timeout_seconds` - время жизни соединения.
- `Redis`
  - `host` - хост сервера Redis.
  - `port` - порт сервера Redis.
  - `username` - логин для auth в Redis (опциональный параметр).
  - `password` - пароль для auth в Redis (опциональный параметр).
  - `poll_delay_ms` - задержка (в миллисекундах) между проверками наличия сообщений в очереди.
  - `read_delay_ms` - задержка (в миллисекундах) между чтениями сообщений из очереди.
  - `queues` - имена очередей (ключи) в Redis.
    - `inbox` - имя входной очереди (для заданий на распознавание).
    - `outbox` - имя выходной очереди (для обработанных задач).
- `Kafka`
  - `group_id` - идентификатор группы потребителей Kafka.
  - `batch_size` - размер батча (количество сообщений), который потребляется за один раз.
  - `bootstrap_servers` - список адресов брокеров Kafka.
  - `auth` - конфигурация для SASL_PLAINTEXT auth (опциональная структура).
    - `username` - имя пользователя (опциональный параметр).
    - `password` - пароль (опциональный параметр).
    - `protocol` - протокол безопасности (например "SASL_PLAINTEXT").
    - `mechanism` - механизм (например "PLAIN").
  - `topics` - имена топиков в Kafka.
    - `input` - имя топика для заданий на распознавание.
    - `output` - имя топика для (не)обработанных заданий.
- `Logging`
  - `log_level` - уровень детализации логов/трассировки.

***Важно!***  
Для S3/Redis/Kafka переопределяйте учетные данные через переменные окружения, чтобы не хранить секреты в YAML.  
В зависимости от вашей конфигурации Redis используйте username, username+password, либо без них.  

Переменные среды:
- APP__S3__ACCESS_KEY="your_s3_login"
- APP__S3__SECRET_KEY="your_secure_s3_password"
- APP__REDIS__USERNAME="your_redis_login"
- APP__REDIS__PASSWORD="your_secure_redis_password"
- APP__KAFKA__AUTH__USERNAME="your_kafka_login"
- APP__KAFKA__AUTH__PASSWORD="your_secure_kafka_password"

### Детали реализации

При старте сервиса запускаются и начинаю выполняться:
- `outbox_daemon`  
  Это демон читающий сообщения из `outbox queue`, и отправляющий их в `Kafka`.  
  Логика работы:  
  При старте сервиса, поднимается экземпляр в отдельном потоке.
  Демон с определенной периодичностью опрашивает `outbox queue`, и при наличии сообщений отправляет их в `Kafka`.
- `kafka_consumer`  
  Это потребитель сообщений из `Kafka`.  
  Логика работы:  
  При старте сервиса, запускается Consumer в отдельном потоке.
  Consumer подключается к `Kafka`, и начинает вычитывать сообщения батчами (размером N).
  Все сообщения батча пушатся в `inbox queue`.
  Далее `inbox queue` опрашивается, пока все задания из батча не уйдут в обработку. Только тогда этот батч коммитится, и берется следующий.

В данный момент очереди `inbox`/`outbox` реализованы как `Redis Lists`, где пишем в хвост очереди, читаем с начала.
В будущем желательно рассмотреть `Redis Stream` или `Apache Pulsar` - это даст гарантии обработки (в отличие от`Redis Lists`).

### Локальный запуск

1) Для установки `Rust` на Unix-подобные системы (MacOS, Linux, ...) - запускаем в терминале команду.
   По окончании загрузки вы получите последнюю стабильную версию Rust для вашей платформы, а так же последнюю версию Cargo.

```shell
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
```

2) Для проверки выполните следующую команду в терминале.  
   В случае успешной установки (шаг 1), вы увидите примерно это `cargo 1.89.0 ...`.

```shell
cargo --version
```

3) Клонируем проект из GitHub, открываем его, и выполняем следующие команды.

Проверяет код на возможность компиляции (без запуска).
```shell
cargo check
```

Сборка + запуск проекта (в режиме релиза с оптимизациями).
```shell
cargo run --release
```

UDP: Если вдруг у вас Windows, посмотрите [Инструкцию тут](https://forge.rust-lang.org/infra/other-installation-methods.html)

### Локальное развертывание

Чтобы развернуть проект локально в `Docker`, вам нужно:

1) Убедиться что `Docker daemon` запущен.
2) Открыть терминал в корне проекта, перейти в директорию `/docker`.
3) Выполнить команду (например `docker compose up -d`) - поднимутся зависимые сервисы (MinIO, Redis, Kafka).
4) Зайти в контейнер Kafka, и выполнить команду создания топиков (например `kafka-topics --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test_input_topic`).
5) Зайти в [MinIO UI](http://localhost:9001/), и создать bucket (например с названием `test`).
6) Запустить сам сервис (инструкция в разделе `Локальный запуск`).
7) Наслаждаться использованием. :wink:
